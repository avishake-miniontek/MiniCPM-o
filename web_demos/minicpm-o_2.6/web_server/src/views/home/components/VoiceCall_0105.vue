<template>
    <ExtraInfo webVersion="websocket_0107" :modelVersion="modelVersion" />
    <div class="voice-page">
        <div class="voice-page-header">
            <div class="header-icon">
                <img src="@/assets/images/voice-icon.png" />
                <span>Audio Choice</span>
            </div>
            <div class="voice-container" v-if="!isCalling">
                <SvgIcon name="voice" class="voice-icon" />
                <SvgIcon name="voice" class="voice-icon" />
                <SvgIcon name="voice" class="voice-icon" />
            </div>
            <div class="voice-container" v-else>
                <Voice
                    :dataArray="dataArray"
                    :isCalling="isCalling"
                    :isPlaying="playing"
                    :configList="videoConfigList"
                    :boxStyle="{ height: '45px' }"
                    :itemStyle="{ width: '3px', margin: '0 1px' }"
                />
            </div>
            <!-- <SelectTimbre v-model:timbre="timbre" v-model:audioData="audioData" v-model:disabled="isCalling" /> -->
        </div>
        <div class="voice-page-output">
            <div class="output-content">
                <ModelOutput v-if="outputData.length > 0" :outputData="outputData" containerClass="output-content" />
            </div>
            <div class="skip-box">
                <DelayTips
                    v-if="delayTimestamp > 200 || delayCount > 2"
                    :delayTimestamp="delayTimestamp"
                    :delayCount="delayCount"
                />
                <LikeAndDislike v-model:feedbackStatus="feedbackStatus" v-model:curResponseId="curResponseId" />
                <SkipBtn :disabled="skipDisabled" @click="skipVoice" />
            </div>
        </div>
        <div class="voice-page-btn">
            <el-button v-show="!isCalling" type="success" :disabled="callDisabled" @click="initRecording">
                {{ callDisabled ? 'Not ready yet, please wait' : 'Call MiniCPM' }}
            </el-button>
            <el-button v-show="isCalling" @click="stopRecording" type="danger">
                <SvgIcon name="phone-icon" className="phone-icon" />
                <span class="btn-text">Hang Up</span>
                <CountDown v-model="isCalling" @timeUp="stopRecording" />
            </el-button>
        </div>
        <IdeasList v-if="showIdeasList" :ideasList="voiceIdeasList" />
    </div>
</template>
<script setup>
    import { sendMessage, stopMessage, uploadConfig } from '@/apis';
    import { encodeWAV } from '@/hooks/useVoice';
    import { getNewUserId, setNewUserId } from '@/hooks/useRandomId';
    import { fetchEventSource } from '@microsoft/fetch-event-source';
    import { MicVAD } from '@ricky0123/vad-web';
    import { videoConfigList, voiceConfigList, voiceIdeasList, showIdeasList } from '@/enums';
    import { getChunkLength } from '@/utils';
    import { mergeBase64ToBlob } from './merge';
    import WebSocketService from '@/utils/websocket';

    let ctrl = new AbortController();
    let socket = null;
    const audioData = ref({
        base64Str: '',
        type: 'mp3'
    }); // Custom sound base64
    const isCalling = defineModel();
    const taskQueue = ref([]);
    const running = ref(false);
    const outputData = ref([]);
    const textQueue = ref('');
    const textAnimationInterval = ref();

    const isFirstReturn = ref(true); // The first audio returned is the audio clip sent from the front end to the back end and needs to be processed separately.

    const audioPlayQueue = ref([]);
    const base64List = ref([]);
    const playing = ref(false);
    const skipDisabled = ref(true);
    const stop = ref(false);
    const timbre = ref([1]);
    const isReturnError = ref(false);
    const allVoice = ref([]);
    const callDisabled = ref(true);

    const feedbackStatus = ref('');
    const curResponseId = ref('');
    const delayTimestamp = ref(0); // Current sending delay
    const delayCount = ref(0); // The number of milliseconds remaining that have not been sent to the interface

    const modelVersion = ref('');

    let audioDOM = new Audio();

    const isEnd = ref(false); // The sse interface is closed, and the model is considered to have completed this return
    // Turn off recording when page unloads
    onBeforeUnmount(() => {
        stopRecording();
    });
    const vadStartTime = ref();
    let myvad = null;
    let vadTimer = null; // The vad timer is used to detect whether the human voice stops within 1 second. If it stops within 1 second, it can be considered as a false vad trigger and ignored directly. If it does not stop within 1 second, it is considered as a human voice and the current conversation is automatically skipped.
    const vadStart = async () => {
        myvad = await MicVAD.new({
            onSpeechStart: () => {
                console.log('Speech start detected');
                if (!skipDisabled.value) {
                    vadTimer && clearTimeout(vadTimer);
                    vadTimer = setTimeout(() => {
                        console.log('Interruption time: ', +new Date());
                        skipVoice();
                    }, 500);
                }
            },
            onSpeechEnd: audio => {
                vadTimer && clearTimeout(vadTimer);
                // debugger;
                // do something with `audio` (Float32Array of audio samples at sample rate 16000)...
            }
        });
        console.log('vad: ', myvad);
        myvad.start();
    };
    onMounted(async () => {
        const { code, message } = await stopMessage();
        if (code !== 0) {
            ElMessage({
                type: 'error',
                message: message,
                duration: 3000,
                customClass: 'system-error'
            });
            return;
        }
        callDisabled.value = false;
    });
    const delay = ms => {
        return new Promise(resolve => setTimeout(resolve, ms));
    };
    const initRecording = async () => {
        uploadUserConfig()
            .then(async () => {
                // A new uid needs to be generated for each call
                setNewUserId();

                outputData.value = [];
                buildConnect();
                isCalling.value = true;
                await delay(100);
                if (socket) {
                    socket.close();
                }
                socket = new WebSocketService(
                    `/ws/stream${window.location.search}&uid=${getNewUserId()}&service=minicpmo-server`
                );
                socket.connect();
                // Wait a moment after establishing a connection before transmitting data
                startRecording();
                if (localStorage.getItem('canStopByVoice') === 'true') {
                    vadStart();
                }
            })
            .catch(() => {});
    };
    let audioContext;
    const analyser = ref();
    const dataArray = ref();
    let mediaRecorder;
    let audioChunks = [];
    const animationFrameId = ref();

    const isFirstPiece = ref(true);

    const startRecording = async () => {
        // Get the user's audio stream
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Create an AudioContext and a MediaStreamAudioSourceNode
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(stream);

        analyser.value = audioContext.createAnalyser();
        // Connecting Audio Nodes to the Analyzer
        source.connect(analyser.value);
        // Analyzer Settings
        analyser.value.fftSize = 256;
        const bufferLength = analyser.value.frequencyBinCount;
        dataArray.value = new Uint8Array(bufferLength);
        // Start drawing sound waves
        drawBars();

        // Create a ScriptProcessorNode to capture audio data
        const processor = audioContext.createScriptProcessor(256, 1, 1);

        processor.onaudioprocess = event => {
            if (!isCalling.value) return;
            if (isReturnError.value) {
                stopRecording();
                return;
            }
            const data = event.inputBuffer.getChannelData(0);
            audioChunks.push(new Float32Array(data));
            // Check if 1 second of data has been collected
            const totalBufferLength = audioChunks.reduce((total, curr) => total + curr.length, 0);
            const chunkLength = getChunkLength(audioContext.sampleRate);
            if (totalBufferLength >= chunkLength) {
                // Merge into a complete data array and crop to 1 second
                const mergedBuffer = mergeBuffers(audioChunks, totalBufferLength);
                const oneSecondBuffer = mergedBuffer.slice(0, chunkLength);
                // Save and process into WAV format
                addQueue(+new Date(), () => saveAudioChunk(oneSecondBuffer, +new Date()));
                // Keep extra data for backup
                audioChunks = [mergedBuffer.slice(chunkLength)];
            }
        };

        source.connect(processor);
        processor.connect(audioContext.destination);
    };
    const stopRecording = () => {
        isCalling.value = false;
        if (animationFrameId.value) {
            cancelAnimationFrame(animationFrameId.value);
        }
        if (audioContext && audioContext.state !== 'closed') {
            audioContext.close();
        }
        ctrl.abort();
        ctrl = new AbortController();
        taskQueue.value = [];
        audioPlayQueue.value = [];
        base64List.value = [];
        isReturnError.value = false;
        skipDisabled.value = true;
        playing.value = false;
        audioDOM.pause();
        stopMessage();
        if (socket) {
            socket.close();
        }
        if (
            outputData.value[outputData.value.length - 1]?.type === 'BOT' &&
            outputData.value[outputData.value.length - 1].audio === '' &&
            allVoice.value.length > 0
        ) {
            outputData.value[outputData.value.length - 1].audio = mergeBase64ToBlob(allVoice.value);
        }
        myvad && myvad.destroy();
    };
    const getStopValue = () => {
        return stop.value;
    };
    const getPlayingValue = () => {
        return playing.value;
    };
    const getStopStatus = () => {
        return localStorage.getItem('canStopByVoice') === 'true';
    };
    const saveAudioChunk = (buffer, timestamp) => {
        return new Promise(resolve => {
            if (!getStopStatus() && getPlayingValue()) {
                resolve();
                return;
            }
            const wavBlob = encodeWAV(buffer, audioContext.sampleRate);
            let reader = new FileReader();
            reader.readAsDataURL(wavBlob);

            reader.onloadend = async function () {
                let base64data = reader.result.split(',')[1];
                if (!base64data) {
                    resolve();
                    return;
                }
                const obj = {
                    uid: getNewUserId(),
                    messages: [
                        {
                            role: 'user',
                            content: [
                                {
                                    type: 'input_audio',
                                    input_audio: {
                                        data: base64data,
                                        format: 'wav',
                                        timestamp: String(timestamp)
                                    }
                                }
                            ]
                        }
                    ]
                };
                socket.send(JSON.stringify(obj));
                socket.on('message', data => {
                    console.log('message: ', data);
                    delayTimestamp.value = +new Date() - timestamp;
                    delayCount.value = taskQueue.value.length;
                    resolve();
                });
                // Send Base64 audio data to the backend
                // try {
                //     await sendMessage(obj);
                //     delayTimestamp.value = +new Date() - timestamp;
                //     delayCount.value = taskQueue.value.length;
                // } catch (err) {}
                // resolve();
            };
        });
    };
    const mergeBuffers = (buffers, length) => {
        const result = new Float32Array(length);
        let offset = 0;
        for (let buffer of buffers) {
            result.set(buffer, offset);
            offset += buffer.length;
        }
        return result;
    };
    // Establishing a connection
    const buildConnect = async () => {
        const obj = {
            messages: [
                {
                    role: 'user',
                    content: [{ type: 'none' }]
                }
            ],
            stream: true
        };
        isEnd.value = false;
        ctrl.abort();
        ctrl = new AbortController();
        const url = `/api/v1/completions${window.location.search}`;
        fetchEventSource(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                service: 'minicpmo-server',
                uid: getNewUserId()
            },
            body: JSON.stringify(obj),
            signal: ctrl.signal,
            openWhenHidden: true,
            async onopen(response) {
                console.log('onopen', response);
                isFirstPiece.value = true;
                isFirstReturn.value = true;
                allVoice.value = [];
                base64List.value = [];
                if (response.status !== 200) {
                    ElMessage({
                        type: 'error',
                        message: 'At limit. Please try again soon.',
                        duration: 3000,
                        customClass: 'system-error'
                    });
                    isReturnError.value = true;
                } else {
                    isReturnError.value = false;
                    // skipDisabled.value = false;
                    drawText();
                }
            },
            onmessage(msg) {
                const data = JSON.parse(msg.data);
                if (data.response_id) {
                    curResponseId.value = data.response_id;
                }
                if (data.choices[0]?.text) {
                    textQueue.value += data.choices[0].text.replace('<end>', '');
                    console.warn('text return time -------------------------------', +new Date());
                }
                // The first return is the audio clip sent by the front end to the back end, which needs to be processed separately
                if (isFirstReturn.value) {
                    console.log('第一次');
                    isFirstReturn.value = false;
                    // If the audio returned by the backend is empty, you need to reconnect
                    if (!data.choices[0].audio) {
                        buildConnect();
                        return;
                    }
                    outputData.value.push({
                        type: 'USER',
                        audio: `data:audio/wav;base64,${data.choices[0].audio}`
                    });
                    outputData.value.push({
                        type: 'BOT',
                        text: '',
                        audio: ''
                    });
                    return;
                }
                if (data.choices[0]?.audio) {
                    console.warn('audio return time -------------------------------', +new Date());
                    if (!getStopValue() && isCalling.value) {
                        skipDisabled.value = false;
                        base64List.value.push(`data:audio/wav;base64,${data.choices[0].audio}`);
                        addAudioQueue(() => truePlay(data.choices[0].audio));
                    }
                    allVoice.value.push(`data:audio/wav;base64,${data.choices[0].audio}`);
                } else {
                    // An exception occurred, reconnect directly
                    buildConnect();
                }
                if (data.choices[0].text.includes('<end>')) {
                    console.log('Received the end tag:', +new Date());
                    if (
                        outputData.value[outputData.value.length - 1]?.type === 'BOT' &&
                        outputData.value[outputData.value.length - 1].audio === '' &&
                        allVoice.value.length > 0
                    ) {
                        outputData.value[outputData.value.length - 1].audio = mergeBase64ToBlob(allVoice.value);
                    }
                }
            },
            onclose() {
                console.log('onclose', +new Date());
                isEnd.value = true;
                outputData.value[outputData.value.length - 1].audio = mergeBase64ToBlob(allVoice.value);
                vadStartTime.value = +new Date();
                if (audioPlayQueue.value.length === 0) {
                    let startIndex = taskQueue.value.findIndex(item => item.time >= vadStartTime.value - 1000);
                    console.log('taskQueue111111111: ', taskQueue.value, startIndex);
                    if (startIndex !== -1) {
                        taskQueue.value = taskQueue.value.slice(startIndex);
                        console.log('Length after cutting:', taskQueue.value, vadStartTime.value);
                    }
                    buildConnect();
                }
            },
            onerror(err) {
                console.log('onerror', err);
                ctrl.abort();
                ctrl = new AbortController();
                throw err;
            }
        });
    };
    const drawText = async () => {
        if (textQueue.value.length > 0) {
            outputData.value[outputData.value.length - 1].text += textQueue.value[0];
            textQueue.value = textQueue.value.slice(1);
        } else {
            cancelAnimationFrame(textAnimationInterval.value);
        }
        textAnimationInterval.value = requestAnimationFrame(drawText);
    };
    // The returned voices are put into the queue and played one by one
    const addAudioQueue = async item => {
        audioPlayQueue.value.push(item);
        if (isFirstPiece.value) {
            await delay(500);
            isFirstPiece.value = false;
        }
        if (audioPlayQueue.value.length > 0 && !playing.value) {
            playing.value = true;
            playAudio();
        }
    };
    // Control playback queue execution
    const playAudio = () => {
        console.log('Remaining Playlists:', audioPlayQueue.value, +new Date());

        if (!isEnd.value && base64List.value.length >= 2) {
            const remainLen = base64List.value.length;
            const blob = mergeBase64ToBlob(base64List.value);
            audioDOM.src = blob;
            audioDOM.play();
            console.error('Playback start time after pre-merge: ', +new Date());
            audioDOM.onended = () => {
                console.error('End time of playback after early merging: ', +new Date());
                base64List.value = base64List.value.slice(remainLen);
                audioPlayQueue.value = audioPlayQueue.value.slice(remainLen);
                playAudio();
            };
            return;
        }
        if (isEnd.value && base64List.value.length >= 2) {
            const blob = mergeBase64ToBlob(base64List.value);
            // let audio = new Audio();
            audioDOM.src = blob;
            audioDOM.play();
            console.error('The start time of playback after the last merge: ', +new Date());
            audioDOM.onended = () => {
                console.error('End time of playback after merging: ', +new Date());
                // URL.revokeObjectURL(url);
                base64List.value = [];
                audioPlayQueue.value = [];
                playing.value = false;
                skipDisabled.value = true;
                if (isCalling.value && !isReturnError.value) {
                    // skipDisabled.value = true;
                    taskQueue.value = [];
                    // Record the interruption time or vad trigger event before interrupting
                    // vadStartTime.value = +new Date();
                    // // After each completion, only the voice that is 1 second ahead of the current moment is retained
                    // console.log(
                    //     'Length before cutting:',
                    //     taskQueue.value.map(item => item.time)
                    // );
                    // let startIndex = taskQueue.value.findIndex(item => item.time >= vadStartTime.value - 1000);
                    // if (startIndex !== -1) {
                    //     taskQueue.value = taskQueue.value.slice(startIndex);
                    //     console.log(
                    //         'Length after cutting:',
                    //         taskQueue.value.map(item => item.time),
                    //         vadStartTime.value
                    //     );
                    // }
                    buildConnect();
                }
            };
            return;
        }
        base64List.value.shift();
        const item = audioPlayQueue.value.shift();
        if (item) {
            item().finally(() => playAudio());
        } else {
            playing.value = false;
            if (isEnd.value) {
                console.warn('play done................');
                skipDisabled.value = true;
            }
            // Start the next connection after playback is completed and the call is in progress and the interface does not return an error
            if (isEnd.value && isCalling.value && !isReturnError.value) {
                // skipDisabled.value = true;
                taskQueue.value = [];
                // Record the interruption time or vad trigger event before interrupting
                // vadStartTime.value = +new Date();
                // // After each completion, only the voice that is 1 second ahead of the current moment is retained
                // console.log(
                //     'Length before cutting:',
                //     taskQueue.value.map(item => item.time)
                // );
                // let startIndex = taskQueue.value.findIndex(item => item.time >= vadStartTime.value - 1000);
                // if (startIndex !== -1) {
                //     taskQueue.value = taskQueue.value.slice(startIndex);
                //     console.log(
                //         'Length after cutting:',
                //         taskQueue.value.map(item => item.time),
                //         vadStartTime.value
                //     );
                // }
                buildConnect();
            }
        }
    };

    // Play Audio
    const truePlay = async voice => {
        return new Promise(resolve => {
            audioDOM.src = 'data:audio/wav;base64,' + voice;
            console.error('Playback start time:', +new Date());
            audioDOM
                .play()
                .then(() => {
                    // console.error('Playback end time: ', +new Date());
                })
                .catch(error => {
                    resolve();
                    if (error.name === 'NotAllowedError' || error.name === 'SecurityError') {
                        console.error('User interaction required or permission issue:', error);
                        ElMessage.warning('Audio playback failed');
                    } else {
                        console.error('Error playing audio:', error);
                    }
                });

            audioDOM.onended = () => {
                console.error('Playback end time: ', +new Date());
                // URL.revokeObjectURL(url);
                resolve();
            };
        });
    };
    // When the number of tasks in the queue is greater than 0, start processing the tasks in the queue
    const addQueue = (time, item) => {
        taskQueue.value.push({ func: item, time });
        if (taskQueue.value.length > 0 && !running.value) {
            running.value = true;
            processQueue();
        }
    };
    const processQueue = () => {
        const item = taskQueue.value.shift();
        if (item?.func) {
            item.func().then(() => {
                console.warn('shift!!!!!!!!!');
                processQueue();
            });
        } else {
            running.value = false;
        }
    };
    const drawBars = () => {
        // The getByteFrequencyData() method of the AnalyserNode interface copies the current frequency data into the passed Uint8Array (unsigned byte array).
        analyser.value.getByteFrequencyData(dataArray.value);
        animationFrameId.value = requestAnimationFrame(drawBars);
    };
    // Skip the current segment
    const skipVoice = async () => {
        // Record the interruption time or vad trigger event before interrupting
        vadStartTime.value = +new Date();
        if (!skipDisabled.value) {
            if (
                outputData.value[outputData.value.length - 1]?.type === 'BOT' &&
                outputData.value[outputData.value.length - 1].audio === ''
            ) {
                outputData.value[outputData.value.length - 1].audio = mergeBase64ToBlob(allVoice.value);
            }
            base64List.value = [];
            audioPlayQueue.value = [];
            // After skipping, only the audio clips from two seconds after the current time point are retained
            console.log(
                'Length before cutting:',
                taskQueue.value.map(item => item.time)
            );
            let startIndex = taskQueue.value.findIndex(item => item.time >= vadStartTime.value - 1000);
            if (startIndex !== -1) {
                taskQueue.value = taskQueue.value.slice(startIndex);
                console.log(
                    'Length after cutting:',
                    taskQueue.value.map(item => item.time),
                    vadStartTime.value
                );
            }
            stop.value = true;
            audioDOM.pause();
            setTimeout(() => {
                skipDisabled.value = true;
            }, 300);
            try {
                playing.value = false;
                await stopMessage();
                stop.value = false;
                // playing.value = false;
                buildConnect();
                // cancelAnimationFrame(animationFrameId.value);
            } catch (err) {}
        }
    };
    // Each call first uploads the current user configuration
    const uploadUserConfig = async () => {
        if (!localStorage.getItem('configData')) {
            return new Promise(resolve => resolve());
        }
        const {
            videoQuality,
            useAudioPrompt,
            voiceClonePrompt,
            assistantPrompt,
            vadThreshold,
            audioFormat,
            base64Str
        } = JSON.parse(localStorage.getItem('configData'));
        const obj = {
            messages: [
                {
                    role: 'user',
                    content: [
                        {
                            type: 'input_audio',
                            input_audio: {
                                data: base64Str,
                                format: audioFormat
                            }
                        },
                        {
                            type: 'options',
                            options: {
                                hd_video: videoQuality,
                                use_audio_prompt: useAudioPrompt,
                                vad_threshold: vadThreshold,
                                voice_clone_prompt: voiceClonePrompt,
                                assistant_prompt: assistantPrompt
                            }
                        }
                    ]
                }
            ]
        };
        const { code, message, data } = await uploadConfig(obj);
        modelVersion.value = data?.choices?.content || '';
        return new Promise((resolve, reject) => {
            if (code !== 0) {
                ElMessage({
                    type: 'error',
                    message: message,
                    duration: 3000,
                    customClass: 'system-error'
                });
                reject();
            } else {
                resolve();
            }
        });
    };
</script>
<style lang="less">
    .voice-page {
        flex: 1;
        height: 100%;
        display: flex;
        flex-direction: column;
        &-header {
            display: flex;
            align-items: center;
            padding: 0 16px 16px;
            box-shadow: 0 0.5px 0 0 #e0e0e0;
            margin-bottom: 16px;
            justify-content: space-between;
            .header-icon {
                display: flex;
                align-items: center;
                img {
                    width: 24px;
                    height: 24px;
                    margin-right: 8px;
                }
                span {
                    color: rgba(23, 23, 23, 0.9);
                    font-family: PingFang SC;
                    font-size: 16px;
                    font-style: normal;
                    font-weight: 500;
                    line-height: normal;
                    margin-right: 40px;
                    flex-shrink: 0;
                }
            }
            .voice-container {
                display: flex;
                .voice-icon {
                    width: 191px;
                    height: 45px;
                }
            }
        }
        &-output {
            flex: 1;
            height: 0;
            padding: 0 16px;
            margin-bottom: 16px;
            display: flex;
            flex-direction: column;
            .output-content {
                flex: 1;
                overflow: auto;
            }
            .skip-box {
                display: flex;
                align-items: center;
                justify-content: flex-end;
                margin-top: 16px;
            }
        }
        &-btn {
            text-align: center;
            padding: 8px 0;
            .el-button {
                width: 284px;
                height: 46px;
                border-radius: 8px;
            }
            .el-button.el-button--success {
                background: #647fff;
                border-color: #647fff;
                &:hover {
                    opacity: 0.8;
                }
                span {
                    color: #fff;
                    font-family: PingFang SC;
                    font-size: 16px;
                    font-style: normal;
                    font-weight: 500;
                    line-height: normal;
                }
            }
            .el-button.el-button--success.is-disabled {
                background: #f3f3f3;
                border-color: #f3f3f3;
                span {
                    color: #d1d1d1;
                }
            }
            .el-button.el-button--danger {
                border-color: #dc3545;
                background-color: #dc3545;
                color: #ffffff;
                font-family: PingFang SC;
                font-size: 16px;
                font-style: normal;
                font-weight: 500;
                line-height: normal;
                .phone-icon {
                    margin-right: 10px;
                }
                .btn-text {
                    margin-right: 10px;
                }
                .btn-desc {
                    margin-right: 16px;
                }
                .time {
                    display: flex;
                    align-items: center;
                    .time-minute,
                    .time-second {
                        width: 26px;
                        height: 26px;
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        border-radius: 3.848px;
                        background: rgba(47, 47, 47, 0.5);
                    }
                    .time-colon {
                        margin: 0 3px;
                    }
                }
            }
        }
    }
</style>
